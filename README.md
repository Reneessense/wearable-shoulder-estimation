# Wearable Shoulder Joint Angle Estimation System  
基于可穿戴织物传感器的肩关节角度估计系统

## 📌 Introduction  
This repository contains the full pipeline for estimating shoulder joint angles using a wearable textile-based sensor system.  
It includes sensor data reading, preprocessing, synchronization with optical motion capture, model training, and inference.  

本项目基于可穿戴织物拉伸传感器，构建了一个端到端的肩关节角度估计系统，包括数据读取、预处理、光捕同步、模型训练与预测。

## 🗂️ Project Structure

├── src/                      # Python scripts for data reading, preprocessing, training
│   ├── 01_generate_training_data.py     # Read + align sensor and mocap data
│   ├── 02_split_motion.py               # Split long sequence into motion clips
│   ├── 03_merge_motion.py               # Merge or reorganize data segments
│   ├── 04_multihead_lstm_train.py       # Multi-head LSTM training
│   ├── 05_predict.py                    # Load model and predict
│   ├── read_6sensor_data.py / read_16sensor_data.py
│   ├── read_opticla.py                 # Optical mocap CSV reader
│   ├── angle_cal.py                    # Calculate joint angles from markers
│   ├── predict_utils.py                # Batched inference helper
│   └── get_intersection_data.py        # Align timestamps of two modalities
│
├── data/                     # Raw and processed data
│   ├── 20250310_data/                # Merged data after alignment, ready for training
│   └── motion_0407/                  # Motion clips (abduction, flexion, etc.)
│
├── model/                    # Trained model checkpoints
├── README.md                 # This file
├── requirements.txt          # Python dependencies
├── LICENSE                   # License file (e.g. MIT)


## 📁 Data Explanation

This project includes two example folders for data:

- `20250310_data/`  
  - Contains merged sensor + mocap angle data  
  - Used for model training  
  - Processed by `01_generate_training_data.py`

- `motion_0407/`  
  - Contains segmented motion clips (e.g., abduction, flexion)  
  - Used for fine-grained training and evaluation  
  - Generated by `02_split_motion.py`

⚠️ The current sample data contains only single-arm recordings (6 sensors, 9 angles) and does not represent the final model configuration.
    当前示例数据为单侧样本（6传感器，9角度），不代表最终模型配置。


## 🚀 How to Run
1. Clone the repo:
git clone https://github.com/Reneessense/wearable-shoulder-estimation.git
cd wearable-shoulder-estimation

2. Install dependencies:
pip install -r requirements.txt

3. Run the demo pipeline:
Step 1: Read and align raw sensor + mocap data
python src/01_generate_training_data.py

Step 2: Split long sequences into motion segments
python src/02_split_motion.py

Step 3: (Optional) Reorganize or merge segments
python src/03_merge_motion.py

Step 4: Train the multi-head LSTM model
python src/04_multihead_lstm_train.py

Step 5: Load model and predict
python src/05_predict.py


## 📈 Model

The full model is a multi-head LSTM designed to predict **18 shoulder joint angles** from **16-channel stretch sensor** input (covering both shoulders).  
Each output head corresponds to one anatomical angle (e.g., humeral abduction, rotation, flexion).

🔎 **Note:**  
The sample dataset currently included (`data/`) only provides **single-arm data**, with **6 sensor inputs** and **9 target angles**.  
The included training code and examples are configured to work with this reduced setting.  
The full dual-arm version (16→18) is still under testing and will be released in the future.


## 📊 Dataset
Sample synchronized dataset (textile sensor + mocap joint angles) is included in the data/ folder.
This is for demonstration only. Please contact authors for full dataset access if needed.

## 📄 License
MIT License

## ✍️ Author
Xinyi Pu, 2025
Nianchong Qv, 2025
Jiaqi Mo, 2025
