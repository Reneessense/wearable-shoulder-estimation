# Wearable Shoulder Joint Angle Estimation System  
åŸºäºå¯ç©¿æˆ´ç»‡ç‰©ä¼ æ„Ÿå™¨çš„è‚©å…³èŠ‚è§’åº¦ä¼°è®¡ç³»ç»Ÿ

## ğŸ“Œ Introduction  
This repository contains the full pipeline for estimating shoulder joint angles using a wearable textile-based sensor system.  
It includes sensor data reading, preprocessing, synchronization with optical motion capture, model training, and inference.  

æœ¬é¡¹ç›®åŸºäºå¯ç©¿æˆ´ç»‡ç‰©æ‹‰ä¼¸ä¼ æ„Ÿå™¨ï¼Œæ„å»ºäº†ä¸€ä¸ªç«¯åˆ°ç«¯çš„è‚©å…³èŠ‚è§’åº¦ä¼°è®¡ç³»ç»Ÿï¼ŒåŒ…æ‹¬æ•°æ®è¯»å–ã€é¢„å¤„ç†ã€å…‰æ•åŒæ­¥ã€æ¨¡å‹è®­ç»ƒä¸é¢„æµ‹ã€‚

## ğŸ—‚ï¸ Project Structure

â”œâ”€â”€ src/                      # Python scripts for data reading, preprocessing, training
â”‚   â”œâ”€â”€ 01_generate_training_data.py     # Read + align sensor and mocap data
â”‚   â”œâ”€â”€ 02_split_motion.py               # Split long sequence into motion clips
â”‚   â”œâ”€â”€ 03_merge_motion.py               # Merge or reorganize data segments
â”‚   â”œâ”€â”€ 04_multihead_lstm_train.py       # Multi-head LSTM training
â”‚   â”œâ”€â”€ 05_predict.py                    # Load model and predict
â”‚   â”œâ”€â”€ read_6sensor_data.py / read_16sensor_data.py
â”‚   â”œâ”€â”€ read_opticla.py                 # Optical mocap CSV reader
â”‚   â”œâ”€â”€ angle_cal.py                    # Calculate joint angles from markers
â”‚   â”œâ”€â”€ predict_utils.py                # Batched inference helper
â”‚   â””â”€â”€ get_intersection_data.py        # Align timestamps of two modalities
â”‚
â”œâ”€â”€ data/                     # Raw and processed data
â”‚   â”œâ”€â”€ 20250310_data/                # Merged data after alignment, ready for training
â”‚   â””â”€â”€ motion_0407/                  # Motion clips (abduction, flexion, etc.)
â”‚
â”œâ”€â”€ model/                    # Trained model checkpoints
â”œâ”€â”€ README.md                 # This file
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ LICENSE                   # License file (e.g. MIT)


## ğŸ“ Data Explanation

This project includes two example folders for data:

- `20250310_data/`  
  - Contains merged sensor + mocap angle data  
  - Used for model training  
  - Processed by `01_generate_training_data.py`

- `motion_0407/`  
  - Contains segmented motion clips (e.g., abduction, flexion)  
  - Used for fine-grained training and evaluation  
  - Generated by `02_split_motion.py`

âš ï¸ The current sample data contains only single-arm recordings (6 sensors, 9 angles) and does not represent the final model configuration.
    å½“å‰ç¤ºä¾‹æ•°æ®ä¸ºå•ä¾§æ ·æœ¬ï¼ˆ6ä¼ æ„Ÿå™¨ï¼Œ9è§’åº¦ï¼‰ï¼Œä¸ä»£è¡¨æœ€ç»ˆæ¨¡å‹é…ç½®ã€‚


## ğŸš€ How to Run
1. Clone the repo:
git clone https://github.com/Reneessense/wearable-shoulder-estimation.git
cd wearable-shoulder-estimation

2. Install dependencies:
pip install -r requirements.txt

3. Run the demo pipeline:
Step 1: Read and align raw sensor + mocap data
python src/01_generate_training_data.py

Step 2: Split long sequences into motion segments
python src/02_split_motion.py

Step 3: (Optional) Reorganize or merge segments
python src/03_merge_motion.py

Step 4: Train the multi-head LSTM model
python src/04_multihead_lstm_train.py

Step 5: Load model and predict
python src/05_predict.py


## ğŸ“ˆ Model

The full model is a multi-head LSTM designed to predict **18 shoulder joint angles** from **16-channel stretch sensor** input (covering both shoulders).  
Each output head corresponds to one anatomical angle (e.g., humeral abduction, rotation, flexion).

ğŸ” **Note:**  
The sample dataset currently included (`data/`) only provides **single-arm data**, with **6 sensor inputs** and **9 target angles**.  
The included training code and examples are configured to work with this reduced setting.  
The full dual-arm version (16â†’18) is still under testing and will be released in the future.


## ğŸ“Š Dataset
Sample synchronized dataset (textile sensor + mocap joint angles) is included in the data/ folder.
This is for demonstration only. Please contact authors for full dataset access if needed.

## ğŸ“„ License
MIT License

## âœï¸ Author
Xinyi Pu, 2025
Nianchong Qv, 2025
Jiaqi Mo, 2025
